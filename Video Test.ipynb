{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from collections import deque\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import torchvision\n",
    "import ast  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()\n",
    "torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self, num_classes, hidden_size=256, num_layers=1):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "        resnet.fc = nn.Identity()  \n",
    "        self.cnn = resnet\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=512, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, C, H, W = x.shape\n",
    "\n",
    "        x = x.view(batch_size * seq_len, C, H, W)\n",
    "\n",
    "        x = self.cnn(x)  \n",
    "\n",
    "        x = x.view(batch_size, seq_len, -1)\n",
    "\n",
    "        x, _ = self.lstm(x)\n",
    "\n",
    "        x = x[:, -1, :]\n",
    "\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "checkpoint = torch.load(\"dog_pose_model_final.pth\", map_location=device)\n",
    " \n",
    "model = CNN_LSTM(num_classes=3).to(device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "NUM_FRAMES = 8\n",
    "\n",
    "class_labels = {2: \"walking\", 1: \"standing+sitting\", 0: \"resting\"}\n",
    "\n",
    "def predict_from_frames(frames):\n",
    "    if len(frames) < NUM_FRAMES:\n",
    "        return None, None  \n",
    "\n",
    "    frames_tensor = torch.stack(list(frames)).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(frames_tensor)\n",
    "        probabilities = F.softmax(output, dim=1).squeeze(0)\n",
    "\n",
    "    predicted_class = torch.argmax(probabilities).item()\n",
    "    probs_dict = {class_labels[i]: probabilities[i].item() * 100 for i in range(len(class_labels))}\n",
    "\n",
    "    return class_labels[predicted_class], probs_dict\n",
    "\n",
    "def show_video_with_live_predictions(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames_queue = deque(maxlen=NUM_FRAMES)  \n",
    "\n",
    "    predicted_label = \"Loading...\" \n",
    "    probs = {class_labels[i]: 0.0 for i in range(len(class_labels))}\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame_tensor = transform(frame_rgb)\n",
    "        frames_queue.append(frame_tensor)\n",
    "\n",
    "        if len(frames_queue) == NUM_FRAMES:\n",
    "            predicted_label, probs = predict_from_frames(frames_queue)\n",
    "\n",
    "        cv2.putText(frame, f\"Prediction: {predicted_label}\", (50, 50), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        y_offset = 90\n",
    "        for label, prob in probs.items():\n",
    "            cv2.putText(frame, f\"{label}: {prob:.2f}%\", (50, y_offset), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            y_offset += 40\n",
    "\n",
    "        cv2.imshow(\"Video Prediction\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "show_video_with_live_predictions('Test_videos\\Another Five Test Videos\\PR0038747VXYF_20230809000001.mp4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
